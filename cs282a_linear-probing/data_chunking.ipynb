{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import fsspec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting Full Embeddings from AWS and Splitting Into Train/Valid/Test\n",
    "\n",
    "`fsspec` and `h5py` are employed to get the full embeddings hosted on AWS, and `sequences.bed` is loaded into a Pandas DataFrame to split the embeddings into train/valid/test sets and save them. Due to large HDF5 files crashing the Jupyter kernel, files of embeddings and labels are partitioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromosome</th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr18</td>\n",
       "      <td>928386</td>\n",
       "      <td>1059458</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr4</td>\n",
       "      <td>113630947</td>\n",
       "      <td>113762019</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr11</td>\n",
       "      <td>18427720</td>\n",
       "      <td>18558792</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr16</td>\n",
       "      <td>85805681</td>\n",
       "      <td>85936753</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr3</td>\n",
       "      <td>158386188</td>\n",
       "      <td>158517260</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38166</th>\n",
       "      <td>chr19</td>\n",
       "      <td>33204702</td>\n",
       "      <td>33335774</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38167</th>\n",
       "      <td>chr14</td>\n",
       "      <td>41861379</td>\n",
       "      <td>41992451</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38168</th>\n",
       "      <td>chr19</td>\n",
       "      <td>30681544</td>\n",
       "      <td>30812616</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38169</th>\n",
       "      <td>chr14</td>\n",
       "      <td>61473198</td>\n",
       "      <td>61604270</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38170</th>\n",
       "      <td>chr2</td>\n",
       "      <td>129664471</td>\n",
       "      <td>129795543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38171 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chromosome       id_1       id_2 dataset\n",
       "0          chr18     928386    1059458   train\n",
       "1           chr4  113630947  113762019   train\n",
       "2          chr11   18427720   18558792   train\n",
       "3          chr16   85805681   85936753   train\n",
       "4           chr3  158386188  158517260   train\n",
       "...          ...        ...        ...     ...\n",
       "38166      chr19   33204702   33335774    test\n",
       "38167      chr14   41861379   41992451    test\n",
       "38168      chr19   30681544   30812616    test\n",
       "38169      chr14   61473198   61604270    test\n",
       "38170       chr2  129664471  129795543    test\n",
       "\n",
       "[38171 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df = pd.read_table('sequences.bed', names=['chromosome', 'id_1', 'id_2', 'dataset'])\n",
    "index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = index_df[index_df['dataset'] == 'train'].index.to_numpy()\n",
    "valid_indices = index_df[index_df['dataset'] == 'valid'].index.to_numpy()\n",
    "test_indices = index_df[index_df['dataset'] == 'test'].index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 34018, 34019, 34020]),\n",
       " array([34021, 34022, 34023, ..., 36231, 36232, 36233]),\n",
       " array([36234, 36235, 36236, ..., 38168, 38169, 38170]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices, valid_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34021, 2213, 1937)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices), len(valid_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS_url = 'https://cs282-datasets.s3.us-west-1.amazonaws.com/embeddings.h5'\n",
    "# remote_f = fsspec.open(AWS_url, mode='rb')\n",
    "\n",
    "# if hasattr(remote_f, 'open'):\n",
    "#     remote_f = remote_f.open()\n",
    "\n",
    "# f = h5py.File(remote_f)\n",
    "# data = f['embeddings']\n",
    "\n",
    "# print(\"Keys: \", f.keys())\n",
    "# print(\"Shape: \", data.shape)\n",
    "# print(\"First element: \", data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data into chunks of 100 points.\n",
    "# There will be 341 chunks for the train set (340*100 + 1*21 = 34021).\n",
    "# for i in range(341):\n",
    "#     if i < 340:\n",
    "#         indices = train_indices[100*i:100*(i+1)]\n",
    "#     else:\n",
    "#         indices = train_indices[100*i:]\n",
    "#     train_chunk = data[indices]\n",
    "#     train_embeds_f = h5py.File(f'./data/embeds/train_chunk_X{i+1}.h5', 'w')\n",
    "#     train_embeds_f.create_dataset('embeddings', data=train_chunk)\n",
    "#     train_embeds_f.close()\n",
    "#     print(f\"Saved chunk {i+1}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be 23 chunks for the validation set (22*100 + 1*13 = 2213).\n",
    "# for j in range(23):\n",
    "#     if j < 22:\n",
    "#         indices = valid_indices[100*j:100*(j+1)]\n",
    "#     else:\n",
    "#         indices = valid_indices[100*j:]\n",
    "#     valid_chunk = data[indices]\n",
    "#     valid_embeds_f = h5py.File(f'./data/embeds/valid_chunk_X{j+1}.h5', 'w')\n",
    "#     valid_embeds_f.create_dataset('embeddings', data=valid_chunk)\n",
    "#     valid_embeds_f.close()\n",
    "#     print(f\"Saved chunk {j+1}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be 20 chunks for the test set (19*100 + 1*37 = 1937).\n",
    "# for k in range(20):\n",
    "#     if k < 19:\n",
    "#         indices = test_indices[100*k:100*(k+1)]\n",
    "#     else:\n",
    "#         indices = test_indices[100*k:]\n",
    "#     test_chunk = data[indices]\n",
    "#     test_embeds_f = h5py.File(f'./data/embeds/test_chunk_X{k+1}.h5', 'w')\n",
    "#     test_embeds_f.create_dataset('embeddings', data=test_chunk)\n",
    "#     test_embeds_f.close()\n",
    "#     print(f\"Saved chunk {k+1}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_labels_f = h5py.File('dataset_14-lmnb1_4-cpg.h5', 'r')\n",
    "# labels = full_labels_f['128bp_bins']\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be 341 chunks for the train set (340*100 + 1*21 = 34021).\n",
    "# for i in range(341):\n",
    "#     if i < 340:\n",
    "#         indices = train_indices[100*i:100*(i+1)]\n",
    "#     else:\n",
    "#         indices = train_indices[100*i:]\n",
    "#     train_chunk = labels[indices]\n",
    "#     train_labels_f = h5py.File(f'./data/labels/train_chunk_y{i+1}.h5', 'w')\n",
    "#     train_labels_f.create_dataset('128bp_bins', data=train_chunk)\n",
    "#     train_labels_f.close()\n",
    "#     print(f\"Saved chunk {i+1}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be 23 chunks for the validation set (22*100 + 1*13 = 2213).\n",
    "# for j in range(23):\n",
    "#     if j < 22:\n",
    "#         indices = valid_indices[100*j:100*(j+1)]\n",
    "#     else:\n",
    "#         indices = valid_indices[100*j:]\n",
    "#     valid_chunk = labels[indices]\n",
    "#     valid_labels_f = h5py.File(f'./data/labels/valid_chunk_y{j+1}.h5', 'w')\n",
    "#     valid_labels_f.create_dataset('128bp_bins', data=valid_chunk)\n",
    "#     valid_labels_f.close()\n",
    "#     print(f\"Saved chunk {j+1}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be 20 chunks for the test set (19*100 + 1*37 = 1937).\n",
    "# for k in range(20):\n",
    "#     if k < 19:\n",
    "#         indices = test_indices[100*k:100*(k+1)]\n",
    "#     else:\n",
    "#         indices = test_indices[100*k:]\n",
    "#     test_chunk = labels[indices]\n",
    "#     test_labels_f = h5py.File(f'./data/labels/test_chunk_y{k+1}.h5', 'w')\n",
    "#     test_labels_f.create_dataset('128bp_bins', data=test_chunk)\n",
    "#     test_labels_f.close()\n",
    "#     print(f\"Saved chunk {k+1}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
