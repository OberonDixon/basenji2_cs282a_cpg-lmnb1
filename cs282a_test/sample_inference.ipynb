{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Inference on Different Fine-Tuning Models\n",
    "\n",
    "This notebook is intended for CS 182/282A project reviewers to verify that the models run. To re-run experiments to see how the models were trained, please take a look at the subdirectories after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f'./sample_data/test_chunk_X1.h5'\n",
    "f = h5py.File(test_path, 'r')\n",
    "dset = f['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransform(nn.Module):\n",
    "    \"\"\"Takes in input (B, 1536, 896) and outputs predictions (B, 18, 896).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv1d(in_channels=1536, out_channels=18, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv_layer.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.conv_layer.bias)\n",
    "        self.activation = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        out = self.activation(self.conv_layer(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearTransform(\n",
       "  (conv_layer): Conv1d(1536, 18, kernel_size=(1,), stride=(1,))\n",
       "  (activation): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_probe = LinearTransform()\n",
    "trained_probe.load_state_dict(torch.load('../cs282a_linear-probing/first_full_run.pth', map_location=torch.device('cpu')))\n",
    "trained_probe.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[185.4840, 191.4664, 192.6241,  ..., 151.3887, 155.1280, 152.4800],\n",
      "        [161.7277, 163.1386, 169.3251,  ..., 104.0094, 109.2395, 103.1794],\n",
      "        [164.3876, 167.4644, 170.2731,  ..., 130.6068, 136.7782, 134.1537],\n",
      "        ...,\n",
      "        [  5.4140,   5.1493,   7.5385,  ...,   4.1214,   4.5688,   6.1868],\n",
      "        [ 21.0667,  32.2378,  33.6077,  ...,  15.7496,  31.8367,  35.1272],\n",
      "        [ 10.4077,  13.6044,  13.3284,  ...,   6.8675,  11.5857,  14.0709]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[149.2984, 153.1806, 147.6395,  ..., 161.8470, 160.1565, 155.4014],\n",
      "        [167.3268, 170.5730, 169.7932,  ..., 183.3823, 172.8373, 173.1581],\n",
      "        [163.4417, 167.6719, 162.6482,  ..., 163.1466, 160.1153, 159.9908],\n",
      "        ...,\n",
      "        [  8.0236,   8.1998,   8.9862,  ...,   6.2350,   2.3821,   4.0134],\n",
      "        [ 21.2210,  16.4974,  23.3127,  ...,  24.2986,   2.7081,  23.4745],\n",
      "        [  9.4221,   6.9032,   8.4551,  ...,  10.5540,   6.5561,  13.4993]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[120.8197, 123.1387, 126.1641,  ..., 127.0645, 130.0960, 130.1491],\n",
      "        [146.2713, 141.2569, 145.8799,  ..., 150.0836, 154.9389, 154.4115],\n",
      "        [136.7463, 136.2886, 141.4921,  ..., 139.3570, 140.6851, 140.9145],\n",
      "        ...,\n",
      "        [  4.7012,  10.2509,  13.0227,  ...,   1.9024,   3.7089,   3.4383],\n",
      "        [ 48.6627,  85.9316,  88.2326,  ...,  12.0444,  11.9547,  21.7704],\n",
      "        [ 10.2859,  20.4306,  25.8561,  ...,   1.5197,   1.3879,   1.8796]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[100.8116,  98.4364, 105.6130,  ...,  70.1928,  72.7492,  73.1145],\n",
      "        [ 90.0530,  89.9671,  98.5574,  ...,  72.6990,  78.8294,  77.3891],\n",
      "        [ 90.0806,  93.7803,  98.7273,  ...,  80.5035,  82.4950,  83.2536],\n",
      "        ...,\n",
      "        [ 15.9081,  18.4429,  16.2002,  ...,  25.1864,  23.0018,  24.3828],\n",
      "        [ 94.0537, 103.9371,  79.0741,  ..., 136.6346, 111.6565, 100.1512],\n",
      "        [ 18.8396,  23.7084,  16.2532,  ...,  33.6626,  29.0348,  28.1579]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[ 86.4153,  91.5404,  91.4072,  ...,  82.5384,  88.6827,  91.5116],\n",
      "        [ 79.4135,  88.4076,  87.6532,  ...,  87.0676,  86.8411,  87.0274],\n",
      "        [ 93.2469, 100.4391, 104.4680,  ...,  94.8033,  98.4222, 102.8869],\n",
      "        ...,\n",
      "        [ 13.2580,  12.9110,  15.1440,  ...,  16.4358,  18.8632,  26.4835],\n",
      "        [ 93.0443,  91.1949, 101.4605,  ...,  83.9203, 108.7101, 132.0352],\n",
      "        [ 12.0665,   8.9235,  12.2126,  ...,  25.4150,  31.5540,  44.8951]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[95.1763, 94.0647, 90.4310,  ..., 81.3349, 78.1558, 83.8899],\n",
      "        [92.2096, 88.1313, 87.2131,  ..., 76.4903, 78.3972, 82.9638],\n",
      "        [95.8457, 94.7216, 95.8633,  ..., 96.8638, 96.4910, 99.7771],\n",
      "        ...,\n",
      "        [10.9105, 15.5763,  9.5498,  ..., 44.8753, 22.5085, 20.0600],\n",
      "        [59.3324, 78.7221, 33.5512,  ..., 77.9804, 65.0374, 62.2979],\n",
      "        [11.4042, 19.6713,  8.0084,  ..., 57.0792, 42.4545, 38.5559]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[160.9746, 160.0829, 160.6598,  ..., 181.6986, 195.7034, 194.6177],\n",
      "        [167.6630, 160.0454, 153.9482,  ..., 189.8278, 199.7147, 196.7443],\n",
      "        [183.9344, 177.7832, 179.2694,  ..., 185.6347, 195.0712, 192.9830],\n",
      "        ...,\n",
      "        [ 13.2508,   7.4765,   6.3877,  ...,   6.2613,   8.5127,  10.0019],\n",
      "        [ 99.3792,  69.3431,  54.9305,  ...,  19.0672,  24.7440,  20.3776],\n",
      "        [ 23.0416,  14.9186,  10.8556,  ...,   8.2470,   7.5086,   6.7360]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[135.1252, 137.0820, 140.1319,  ..., 190.4521, 184.7673, 175.8489],\n",
      "        [156.5947, 155.8044, 158.5527,  ..., 164.3048, 159.5437, 152.7644],\n",
      "        [141.1341, 141.7263, 144.3717,  ..., 194.2375, 188.1880, 177.7010],\n",
      "        ...,\n",
      "        [  7.2904,   7.2503,   7.8259,  ...,   5.6125,   1.6961,   0.6262],\n",
      "        [ 16.3991,  17.5997,  20.4587,  ...,  46.9552,  35.1460,  33.3025],\n",
      "        [  5.0116,   5.1909,   6.1729,  ...,  13.3077,   9.1349,   9.2563]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[143.9242, 143.7551, 141.8314,  ..., 115.1826, 113.4652, 112.2225],\n",
      "        [114.2138, 117.7131, 116.0454,  ..., 112.4954, 111.7554, 109.6283],\n",
      "        [121.8019, 120.1443, 121.2454,  ..., 115.8774, 115.6160, 111.3573],\n",
      "        ...,\n",
      "        [  2.5956,   0.9622,   5.9651,  ...,  17.9699,  18.9164,  16.4963],\n",
      "        [ 24.5584,  21.8136,  41.0147,  ...,  90.4778,  84.8802,  69.6820],\n",
      "        [  7.9608,   5.6379,  13.2608,  ...,  36.7875,  37.9844,  33.5178]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[185.6256, 182.1289, 182.6872,  ..., 191.3248, 193.2050, 186.1759],\n",
      "        [183.9882, 184.2827, 177.4371,  ..., 202.1972, 202.4642, 196.5477],\n",
      "        [174.1942, 171.5017, 171.2132,  ..., 182.9038, 184.1622, 179.8323],\n",
      "        ...,\n",
      "        [  1.7463,   9.0015,  20.5801,  ...,   3.1847,   2.5343,   3.4549],\n",
      "        [  3.1974,  39.1155,  38.2550,  ...,  12.2985,  14.7351,  24.5370],\n",
      "        [  6.0614,  19.0701,  30.3728,  ...,   7.8549,   9.0848,  11.7355]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[136.6294, 135.8548, 129.5853,  ..., 181.1891, 172.7730, 173.7408],\n",
      "        [146.4553, 150.8674, 144.2109,  ..., 174.0476, 167.3086, 171.6453],\n",
      "        [138.6785, 136.6969, 134.1494,  ..., 161.9776, 154.7500, 154.2588],\n",
      "        ...,\n",
      "        [  3.0597,   2.9064,   1.0467,  ...,   3.3320,   1.1611,   1.4181],\n",
      "        [ 17.3120,  19.5566,  13.3104,  ...,   6.0573,   5.4764,  12.1917],\n",
      "        [  6.5119,   6.2717,   4.2419,  ...,   4.2332,   4.3855,   5.1335]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[176.0033, 176.9435, 174.6412,  ..., 187.3951, 189.0268, 194.0254],\n",
      "        [182.0115, 187.0910, 177.0773,  ..., 172.8142, 174.9541, 178.9300],\n",
      "        [156.3321, 155.9854, 152.8830,  ..., 167.6589, 169.9520, 174.4812],\n",
      "        ...,\n",
      "        [  1.0682,   0.7404,   2.1934,  ...,   3.2725,   4.2622,   1.9217],\n",
      "        [ 17.7647,  22.4858,  37.3967,  ...,  29.1791,  35.7003,  28.0401],\n",
      "        [ 11.4928,   9.7706,  12.3369,  ...,  13.1100,  16.1508,  11.2966]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[194.1808, 202.5147, 205.6476,  ..., 203.6097, 206.6658, 203.7510],\n",
      "        [191.9242, 197.6113, 197.9460,  ..., 215.8603, 220.5305, 219.6940],\n",
      "        [185.1368, 189.0736, 191.6665,  ..., 191.9217, 196.8814, 195.3182],\n",
      "        ...,\n",
      "        [  3.7183,   4.4191,   4.9270,  ...,   3.0797,   1.4238,   0.5711],\n",
      "        [ 28.9809,  31.5952,  31.4661,  ...,  20.4664,  14.4561,   3.9761],\n",
      "        [ 24.6486,  17.1652,  11.4356,  ...,  10.2961,   9.4126,   6.8927]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[210.6259, 210.0385, 208.8145,  ..., 210.2667, 214.7433, 207.9783],\n",
      "        [207.1029, 204.0776, 205.0182,  ..., 195.1041, 199.3316, 193.2540],\n",
      "        [190.0446, 188.7508, 186.9702,  ..., 194.2193, 194.2372, 193.1808],\n",
      "        ...,\n",
      "        [  6.4718,   3.9164,   4.0021,  ...,   3.6287,   5.2942,   5.9848],\n",
      "        [ 20.2461,   1.9711,   5.4015,  ...,  14.0057,  41.9240,  38.8822],\n",
      "        [ 11.1230,   4.5649,   4.8700,  ...,   5.4452,  13.2753,   9.8852]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[103.7457, 106.9671, 103.7989,  ...,  76.6075,  73.4294,  77.3474],\n",
      "        [ 98.8727, 102.7212,  95.7450,  ...,  81.6389,  81.2803,  77.1050],\n",
      "        [114.5410, 119.7391, 115.8308,  ...,  82.1918,  76.5755,  76.6090],\n",
      "        ...,\n",
      "        [ 10.6931,  14.0801,  12.8923,  ...,  28.0397,  21.7476,  30.3241],\n",
      "        [ 97.5001, 105.4857, 104.4188,  ..., 122.8987,  98.3214, 128.3224],\n",
      "        [ 14.7479,  14.8297,  15.7180,  ...,  36.4556,  25.6846,  40.8785]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[ 91.5988,  88.6578,  91.2273,  ...,  84.8910,  81.9346,  87.2795],\n",
      "        [ 84.8201,  81.7445,  83.9750,  ...,  86.5843,  83.2693,  86.3647],\n",
      "        [100.2505,  96.6219,  99.1552,  ...,  98.0533,  94.8482,  95.8824],\n",
      "        ...,\n",
      "        [  8.9786,   9.0102,   7.8557,  ...,  11.9987,  11.4539,  13.1633],\n",
      "        [ 50.2174,  52.1963,  45.0195,  ...,  51.2622,  61.7287,  69.8892],\n",
      "        [ 14.8969,  17.6172,  13.4850,  ...,  16.2387,  19.6914,  24.4033]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[136.9517, 133.8692, 130.5684,  ..., 121.6477, 121.9856, 122.5980],\n",
      "        [118.5258, 119.1527, 117.2553,  ..., 140.9175, 139.8342, 143.4988],\n",
      "        [155.1589, 156.0416, 151.2865,  ..., 137.2667, 138.4543, 139.5754],\n",
      "        ...,\n",
      "        [  5.4858,   8.9273,   6.5205,  ...,  21.7881,  13.7627,   5.4378],\n",
      "        [ 40.5386,  45.9276,  33.2505,  ..., 108.6880,  82.6607,  35.4739],\n",
      "        [ 10.8136,  14.8749,   9.2885,  ...,  39.0681,  20.5710,   6.7025]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[105.8478, 102.5805, 100.0712,  ..., 131.7265, 131.5739, 129.5936],\n",
      "        [106.8062, 102.1125, 105.4622,  ..., 117.8459, 122.9937, 117.6972],\n",
      "        [122.1957, 119.2631, 116.2481,  ..., 148.8608, 152.8770, 152.4770],\n",
      "        ...,\n",
      "        [  6.8704,   7.1327,  12.7816,  ...,   9.8082,  11.4898,  10.8973],\n",
      "        [ 61.2758,  72.1420, 128.8212,  ...,  54.6988,  55.9743,  48.1546],\n",
      "        [  3.4916,   5.3792,  17.6700,  ...,   8.4775,   9.6041,   8.0654]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[158.2212, 154.3656, 150.4650,  ..., 148.1606, 146.3219, 142.1782],\n",
      "        [123.5908, 119.1272, 125.0653,  ..., 139.0609, 135.8995, 133.9052],\n",
      "        [166.1274, 160.6514, 162.2100,  ..., 157.9064, 153.8508, 152.9004],\n",
      "        ...,\n",
      "        [  7.6560,   4.9750,   7.4695,  ...,   8.4624,   8.4595,   8.0842],\n",
      "        [ 53.1712,  24.9585,  23.2711,  ...,  44.3170,  42.2589,  45.5707],\n",
      "        [ 19.0669,   9.3996,   9.3469,  ...,  17.6809,  17.6098,  19.2366]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([[126.5435, 123.8108, 120.9309,  ..., 103.8299,  99.9147,  99.5980],\n",
      "        [126.0537, 121.5540, 123.3926,  ...,  91.3941,  95.0367,  90.3676],\n",
      "        [144.4781, 142.1303, 138.9446,  ..., 112.9538, 110.3071, 109.6088],\n",
      "        ...,\n",
      "        [ 11.6682,  13.2369,   7.3810,  ...,   7.7217,  16.9870,  29.8214],\n",
      "        [112.2037, 122.5116,  82.9366,  ...,  59.8412, 112.5167, 147.7665],\n",
      "        [ 15.6564,  18.9398,   9.1556,  ...,  11.2784,  31.2660,  50.1304]],\n",
      "       grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dset)):\n",
    "    inputs = torch.Tensor(dset[i])\n",
    "    predictions = trained_probe(inputs.transpose(0,1))\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 1D CNN + Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(MLPModel, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1x1', nn.Conv1d(1536, 500, 1)),\n",
    "            ('gelu1', nn.GELU()),\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('fc1', nn.Linear(448000, 18))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModel(\n",
       "  (layers): Sequential(\n",
       "    (conv1x1): Conv1d(1536, 500, kernel_size=(1,), stride=(1,))\n",
       "    (gelu1): GELU(approximate='none')\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=448000, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPModel()\n",
    "mlp_model.load_state_dict(torch.load('../cs282a_conv1d_perceptron/model_20231128_063541_2'))\n",
    "mlp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[185.1219, 165.0662, 172.5271, 169.7588, 183.6932, 167.8994, 186.5149,\n",
      "         182.3538, 168.5229, 176.6938, 176.6521, 160.2308,  13.9360,   9.6113,\n",
      "          67.5173,   3.1071,  77.7010,   9.5490]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[150.9066, 182.2299, 153.4019, 159.0182, 148.4989, 159.1315, 152.8746,\n",
      "         141.5418, 171.3732, 160.7533, 153.8532, 165.8867,  14.1168,   9.8270,\n",
      "         125.0091,   3.1626,  92.7511,   8.0396]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[130.3526, 155.1663, 149.7936, 150.6678, 148.9104, 131.7747, 154.3013,\n",
      "         136.7864, 141.5564, 164.5454, 136.9123, 130.3914,   9.1082,   4.9956,\n",
      "         150.3599,   3.4720, 143.1677,   9.8213]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[102.7417, 111.9067, 121.7186, 124.8033, 115.8242, 115.5144, 118.2789,\n",
      "         117.0127, 105.2756, 111.5346, 111.8413, 114.4374,   2.5230,   3.3681,\n",
      "         207.3947,   9.7393, 218.1850,  23.6601]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 84.6395,  82.0686,  96.8328, 113.9138, 110.0792,  96.3231,  90.2322,\n",
      "          94.9772,  88.0948,  95.5470,  88.3441,  92.7931,   1.3467,   1.8852,\n",
      "         184.6552,  16.5562, 184.0349,  35.2706]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 87.1823,  97.1128, 101.5982, 117.5979, 115.5824,  93.8905, 106.9655,\n",
      "          99.9854,  91.7273, 109.8873,  99.9236,  90.8806,   5.0248,   3.0187,\n",
      "         161.2382,  10.5669, 119.9536,  23.1577]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[185.3415, 183.3734, 194.7859, 173.4577, 170.0484, 199.4192, 174.9852,\n",
      "         184.2457, 192.3940, 170.8158, 195.1151, 200.2727,  12.9895,   8.0903,\n",
      "         159.5181,   2.2665, 166.5328,   7.1571]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[170.5139, 179.8052, 185.2793, 170.5000, 168.7476, 182.2724, 169.1534,\n",
      "         175.8705, 183.8721, 174.3668, 181.0385, 181.5280,  16.1655,   7.5988,\n",
      "         127.1855,   2.2231, 165.3930,   7.6034]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[144.6516, 147.8305, 145.1608, 145.3560, 154.1574, 131.7404, 156.6112,\n",
      "         144.6839, 140.7207, 156.2130, 141.1035, 129.4347,   8.8361,   6.6321,\n",
      "          99.3793,   4.0983,  89.2193,  11.5478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[186.9887, 196.7114, 171.8672, 171.1920, 173.6098, 181.8882, 174.4379,\n",
      "         172.2551, 192.5135, 174.3240, 181.8516, 186.6855,  18.4148,  11.7692,\n",
      "          72.3481,   2.3762,  70.0053,   7.0877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[148.7166, 168.5066, 145.2065, 150.6226, 160.9164, 136.4503, 163.3026,\n",
      "         145.5698, 159.0286, 165.4832, 143.5026, 137.2422,  12.4657,   8.2598,\n",
      "          64.0958,   3.0196,  76.8055,   9.6376]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[193.1502, 189.0345, 169.7618, 169.6732, 176.2460, 176.7584, 178.4139,\n",
      "         181.6789, 187.6559, 174.6407, 175.8907, 179.0203,  18.5674,  10.6637,\n",
      "          41.0500,   2.9023,  68.9649,   8.6107]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[218.3911, 209.9024, 193.1727, 184.4071, 194.1525, 205.1568, 189.0661,\n",
      "         200.0496, 214.3433, 187.4520, 206.2108, 209.7356,  19.5474,  12.6958,\n",
      "          46.2200,   1.8878,  64.8666,   6.2852]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[199.0510, 177.0699, 178.5939, 177.1283, 168.0883, 191.2343, 176.1425,\n",
      "         185.0553, 189.6200, 173.5373, 185.1940, 194.9854,  19.0212,  10.7315,\n",
      "         113.2348,   3.5440, 108.2235,   9.9574]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 87.4366,  93.2120,  95.7852, 113.5667, 105.1071,  94.3404,  95.8380,\n",
      "          93.9522,  89.2421,  99.8143,  87.8130,  94.6264,   3.3396,   2.7070,\n",
      "         205.8871,  12.1040, 194.5348,  26.6553]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 90.3363,  88.1522,  98.6180, 121.3602, 132.0102,  84.2243, 121.5467,\n",
      "          97.2362,  85.1398, 115.6695,  99.5214,  79.7654,   2.9757,   2.6117,\n",
      "         162.8592,  12.5133, 125.2607,  26.9068]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[119.5281, 112.7718, 138.7221, 133.7684, 134.6087, 123.2281, 137.0180,\n",
      "         129.4485, 118.0857, 135.5165, 122.7636, 116.6091,   6.6817,   3.4509,\n",
      "         174.9872,   6.1986, 138.8093,  14.7068]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[109.5213, 104.5999, 126.1309, 119.3128, 109.2695, 125.0667, 116.9407,\n",
      "         126.2750, 110.7513, 111.4432, 114.4767, 120.4912,   1.7671,   1.9201,\n",
      "         208.6101,   9.3484, 230.1896,  22.6205]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[136.0644, 130.2340, 145.1451, 141.8312, 148.3033, 125.5836, 166.7201,\n",
      "         145.7545, 124.9490, 161.5542, 136.1903, 118.4920,   6.9031,   5.7136,\n",
      "         131.2041,   3.6600,  99.5057,  10.4313]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[113.0756, 104.3715, 128.3481, 122.1380, 111.1741, 125.9933, 118.4776,\n",
      "         121.4610, 113.0003, 117.8814, 110.2180, 124.3502,   3.0312,   2.7909,\n",
      "         224.7243,   9.2903, 224.1358,  20.7252]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dset)):\n",
    "    inputs = torch.Tensor(dset[i]).reshape(1,896,1536)\n",
    "    predictions = mlp_model(inputs.transpose(1,2))\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1d CNN + Max Pooling + Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModelPooling(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(MLPModelPooling, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1x1', nn.Conv1d(1536, 500, 1)),\n",
    "            ('gelu1', nn.GELU()),\n",
    "            ('maxpool1', nn.MaxPool1d(896)),\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('fc1', nn.Linear(500, 18))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPModelPooling(\n",
       "  (layers): Sequential(\n",
       "    (conv1x1): Conv1d(1536, 500, kernel_size=(1,), stride=(1,))\n",
       "    (gelu1): GELU(approximate='none')\n",
       "    (maxpool1): MaxPool1d(kernel_size=896, stride=896, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=500, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_model = MLPModelPooling()\n",
    "pool_model.load_state_dict(torch.load('../cs282a_perceptron-maxpool/model_20231128_072156_3'))\n",
    "pool_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dset)):\n",
    "    inputs = torch.Tensor(dset[i]).reshape(1,896,1536)\n",
    "    predictions = pool_model(inputs.transpose(1,2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model, heads, forward_expansion, dropout, max_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, forward_expansion * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(forward_expansion * d_model, d_model)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Additional linear layer for output transformation\n",
    "        self.output_transform = nn.Linear(d_model, 18)\n",
    "\n",
    "        # Adaptive pooling layer to handle sequence length\n",
    "        self.sequence_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x, enc_out=None, src_mask=None, trg_mask=None):\n",
    "        attention_output, _ = self.attention(x, x, x, attn_mask=trg_mask)\n",
    "        query = self.dropout(self.norm1(attention_output + x))\n",
    "\n",
    "        out = self.feed_forward(query)\n",
    "        out = self.dropout(self.norm2(out + query))\n",
    "\n",
    "        out_transformed = self.output_transform(out)\n",
    "\n",
    "        out_pooled = self.sequence_pooling(out_transformed.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        return out_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1536, out_features=1536, bias=True)\n",
       "  )\n",
       "  (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (feed_forward): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (output_transform): Linear(in_features=1536, out_features=18, bias=True)\n",
       "  (sequence_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_basenji_transformer = TransformerDecoder(d_model=1536, heads=6, forward_expansion=2, dropout=0.2, max_length=896)\n",
    "trained_filepath  = '../cs282a_self-attention/model_20231128_080512_7'\n",
    "trained_basenji_transformer.load_state_dict(torch.load(trained_filepath))\n",
    "trained_basenji_transformer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dset)):\n",
    "    inputs = torch.Tensor(dset[i]).reshape(1,896,1536)\n",
    "    predictions = trained_basenji_transformer(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs282a_test",
   "language": "python",
   "name": "cs282a_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
